import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np


df =pd.read_csv('Clean_Dataset.csv')
df.head()


df.info()








df['normalized_price'] = np.log(df['price'])


df['airline_idx'], uniques = pd.factorize(df['airline'])
df.head()


unique_cities = pd.unique(df[['source_city', 'destination_city']].values.ravel('K'))

# Create mapping dictionary
city_to_index = {city: idx for idx, city in enumerate(unique_cities)}

# Apply the mapping to both columns
df['source_city_idx'] = df['source_city'].map(city_to_index)
df['destination_city_idx'] = df['destination_city'].map(city_to_index)

df.head()


#indexing departure time
departure_time_to_index = {
    "Late_Night": 5.0,
    "Early_Morning": 0.0,
    "Morning": 1.0,
    "Night": 4.0,
    "Evening": 3.0,
    "Afternoon": 2.0
}

def map_departure_time(departure_time):
    return departure_time_to_index.get(departure_time, None)

df['departure_time_idx'] = df['departure_time'].apply(map_departure_time)
df['arrival_time_idx'] = df['arrival_time'].apply(map_departure_time)

df.head()


df['class_idx'] = df['class'].apply(lambda x: 0.0 if x == 'Economy' else 1.0)
df.head()


stops_to_index = {
    "zero": 0.0,
    "one": 1.0,
    "two_or_more": 2.0,
}

# Function to map stops
def map_stops(stops):
    return stops_to_index.get(stops, None)

# Apply the function to create a new column
df['stops_idx'] = df['stops'].apply(map_stops)
df.head()





total = df['airline'].value_counts().reset_index()
total.head()


sns.countplot(df, x='airline', stat='count')
plt.show()


data1=df['source_city'].value_counts().reset_index()
data1.head()


data2=df['destination_city'].value_counts().reset_index()
data2.head()



labels = ['Chennai','Hyderabad','Kolkata','Bangalore','Delhi','Mumbai']

plt.figure(figsize=(20,16))
fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, constrained_layout = True)

ax[0].pie(data1['count'], labels=labels, startangle=45,  autopct='%.2f%%')
ax[0].set_title('Source City')
ax[1].pie(data2['count'], labels=labels, startangle=120, autopct='%.2f%%')
ax[1].set_title('Destination City')

plt.show()


labels = ['Business, Economy']
flight_class=df['class'].value_counts().reset_index()
plt.bar(flight_class['class'], flight_class['count'])
plt.xlabel('Class')
plt.show()


tes = df.groupby(['days_left','class'])['price'].mean().reset_index()
tes.head(10)


economy_data = tes[tes['class'] == 'Economy']
business_data = tes[tes['class'] == 'Business']

fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))

# Plot for Economy class
ax1.plot(economy_data['days_left'], economy_data['price'], color='b', label='Economy')
ax1.set_xlabel('Days Left')
ax1.set_ylabel('Price')
ax1.set_title('Price vs Days Left - Economy Class')
ax1.legend()

# Plot for Business class
ax2.plot(business_data['days_left'], business_data['price'], color='r', label='Business')
ax2.set_xlabel('Days Left')
ax2.set_ylabel('Price')
ax2.set_title('Price vs Days Left - Business Class')
ax2.legend()

# Adjust layout and display plot
plt.tight_layout()
plt.show()


tes2 = df.groupby(['stops','class'])['price'].mean().reset_index()
tes2.head(10)


sns.barplot(df, x='stops',y='price',hue='class')
plt.title('Price To Stops')
plt.show()


# Create a figure for the subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 13),sharex=False, sharey=False)

# Price distribution

# Price KDE plot
sns.kdeplot(df,x='price', hue='class', multiple='stack',ax=axes[0, 0])
axes[0, 0].set_title('Price')

# Duration KDE plot
sns.kdeplot(df,x='duration',hue='class', multiple='stack', ax=axes[0, 1])
axes[0,1 ].set_title('Duration')

# Days left KDE plot
sns.kdeplot(df,x='days_left',hue='class', multiple='stack',ax=axes[1,0 ])
axes[1, 0].set_title('Days Left')

axes[1, 1].axis('off')

plt.tight_layout()
plt.show()


#Create Dataframe for Indexed data
index_df = df[['airline_idx','source_city_idx','departure_time_idx','stops_idx','arrival_time_idx','destination_city_idx','class_idx','duration','days_left','normalized_price']]
index_df.head()


# Select only numeric columns for correlation analysis
numeric_data = index_df.select_dtypes(include=[float, int])

# Calculate the correlation matrix
correlation_matrix = numeric_data.corr()

# Focus on the correlation with the diabetes progression (Y)
correlation_with_Y = correlation_matrix['normalized_price'].sort_values(ascending=False)

print(correlation_with_Y)



plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix of Job Performance')
plt.show()





from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error


X = index_df.drop(columns=['normalized_price']).values
y = index_df['normalized_price'].values


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)



models = ['Linear Regression','Gradient Boosting Regressor','MLP Regressor', 'Random Forest Regressor']
rmses =[]


# Create the model
model = LinearRegression()

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred_lr= model.predict(X_test)

mse = mean_squared_error(y_test, y_pred_lr)
rmse = np.sqrt(mse)
rmses.append(rmse)
print(f"Root Mean Squared Error of Linear Regression Model: {rmse}")


plt.figure(figsize=(10, 6))
plt.scatter(np.exp(y_test), np.exp(y_pred_lr), color='darkorange', label='Predicted vs Actual')
plt.plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
plt.xlabel('Actual Values')
plt.xlabel('data')
plt.ylabel('target')
plt.title('Linear Regression')
plt.legend()
plt.show()





from sklearn.ensemble import GradientBoostingRegressor

# Create the model
gbt_model = GradientBoostingRegressor(n_estimators=100, random_state=0)

# Train the model
gbt_model.fit(X_train, y_train)


y_pred_gbt = gbt_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred_gbt)
rmse = np.sqrt(mse)
rmses.append(rmse)
print(f"Root Mean Squared Error of GBT Model: {rmse}")


plt.figure(figsize=(10, 6))
plt.scatter(np.exp(y_test), np.exp(y_pred_gbt), color='darkorange', label='Predicted vs Actual')
plt.plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
plt.xlabel('Actual Values')
plt.xlabel('data')
plt.ylabel('target')
plt.title('GBT Regressor')
plt.legend()
plt.show()





from sklearn.neural_network import MLPRegressor

# Create the model
mlp_model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, random_state=0)

# Train the model
mlp_model.fit(X_train, y_train)

y_pred_mlp=  mlp_model.predict(X_test)


mse = mean_squared_error(y_test, y_pred_mlp)
rmse = np.sqrt(mse)
rmses.append(rmse)
print(f"Root Mean Squared Error of MLP Model: {rmse}")



plt.figure(figsize=(10, 6))
plt.scatter(np.exp(y_test), np.exp(y_pred_mlp), color='darkorange', label='Predicted vs Actual')
plt.plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
plt.xlabel('Actual Values')
plt.xlabel('data')
plt.ylabel('target')
plt.title('MLP Regressor')
plt.legend()
plt.show()





from sklearn.ensemble import RandomForestRegressor


rf_model = RandomForestRegressor(n_estimators=100,random_state=0)
rf_model.fit(X_train,y_train)
y_pred_rf = rf_model.predict(X_test)


mse = mean_squared_error(y_test, y_pred_rf)
rmse = np.sqrt(mse)
rmses.append(rmse)
print(f"Root Mean Squared Error of Random Forest Model: {rmse}")


plt.figure(figsize=(10, 6))
plt.scatter(np.exp(y_test), np.exp(y_pred_rf), color='darkorange', label='Predicted vs Actual')
plt.plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
plt.xlabel('Actual Values')
plt.xlabel('data')
plt.ylabel('target')
plt.title('Random Forest Regressor')
plt.legend()
plt.show()


print(rmses)


# Create a figure for the subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 13),sharex=False, sharey=False)

# Price distribution

# Price KDE plot
axes[0,0].scatter(np.exp(y_test), np.exp(y_pred_lr), color='darkorange', label='Predicted vs Actual')
axes[0,0].plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
axes[0,0].legend()
axes[0, 0].set_title('Linear Regression')

# Duration KDE plot
axes[0,1].scatter(np.exp(y_test), np.exp(y_pred_gbt), color='darkorange', label='Predicted vs Actual')
axes[0,1].plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
# axes[0,1].xlabel('Actual Values')
# axes[0,1].xlabel('data')
# axes[0,1].ylabel('target')
axes[0,1].legend()
axes[0, 1].set_title('GBT Regressor')

# Days left KDE plot
axes[1,0].scatter(np.exp(y_test), np.exp(y_pred_gbt), color='darkorange', label='Predicted vs Actual')
axes[1,0].plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
# axes[1,0].xlabel('Actual Values')
# axes[1,0].xlabel('data')
# axes[1,0].ylabel('target')
axes[1,0].legend()
axes[1,0].set_title('MLP Regressor')

axes[1,1].scatter(np.exp(y_test), np.exp(y_pred_rf), color='darkorange', label='Predicted vs Actual')
axes[1,1].plot([np.min(np.exp(y_test)), np.max(np.exp(y_test))], [np.min(np.exp(y_test)), np.max(np.exp(y_test))], color='navy', lw=2, label='Ideal Fit')
# axes[1,1].xlabel('Actual Values')
# axes[1,1].xlabel('data')
# axes[1,1].ylabel('target')
axes[1,1].legend()
axes[1,1].set_title('Random Forest Regressor')

plt.tight_layout()
plt.show()


plt.figure(figsize=(10,6))
plt.bar(models, rmses)
plt.xlabel('Model')
plt.ylabel("RMSE")
plt.title('Model RMSE')
plt.show()


index_df.head()
temp_df = index_df.drop(columns=['normalized_price'])
temp_df.head()



# Get feature importances and feature names
feature_importances = rf_model.feature_importances_
feature_names = temp_df.columns
sorted_idx = np.argsort(feature_importances)[::1]

# Plot feature importances
plt.figure(figsize=(8, 6))
plt.barh(feature_names[sorted_idx], feature_importances[sorted_idx], align='center')
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Random Forest Feature Importance')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability if needed
plt.show()

